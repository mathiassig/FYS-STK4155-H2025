{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4005770",
   "metadata": {},
   "source": [
    "# Exercises week 35\n",
    "\n",
    "## Deriving and Implementing Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1b589",
   "metadata": {},
   "source": [
    "This week you will be deriving the analytical expressions for linear regression, building up the model from scratch. This will include taking several derivatives of products of vectors and matrices. Such derivatives are central to the optimization of many machine learning models. Although we will often use automatic differentiation in actual calculations, to be able to have analytical expressions is extremely helpful in case we have simpler derivatives as well as when we analyze various properties (like second derivatives) of the chosen cost functions.\n",
    "\n",
    "Vectors are always written as boldfaced lower case letters and matrices as upper case boldfaced letters. You will find useful the notes from week 35 on derivatives of vectors and matrices. See also the textbook of Faisal at al, chapter 5 and in particular sections 5.3-5.5 at <https://github.com/CompPhysics/MachineLearning/blob/master/doc/Textbooks/MathMLbook.pdf>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e92bf9",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "\n",
    "After completing these exercises, you will know how to\n",
    "- Take the derivatives of simple products between vectors and matrices\n",
    "- Implement OLS using the analytical expressions\n",
    "- Create a feature matrix from a set of data\n",
    "- Create a feature matrix for a polynomial model\n",
    "- Evaluate the MSE score of various model on training and test data, and comparing their performance\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Complete the following exercises while working in a jupyter notebook. Then, in canvas, include\n",
    "- The jupyter notebook with the exercises completed\n",
    "- An exported PDF of the notebook (https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_export-your-jupyter-notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9209d",
   "metadata": {},
   "source": [
    "## How to take derivatives of Matrix-Vector expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3712e",
   "metadata": {},
   "source": [
    "In these exercises it is always useful to write out with summation indices the various quantities. Take also a look at the weekly slides from week 35 and the various examples included there.\n",
    "\n",
    "As an example, consider the function\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) =\\boldsymbol{A}\\boldsymbol{x},\n",
    "$$\n",
    "\n",
    "which reads for a specific component $f_i$ (we define the matrix $\\boldsymbol{A}$ to have dimension $n\\times n$ and the vector $\\boldsymbol{x}$ to have length $n$)\n",
    "\n",
    "$$\n",
    "f_i =\\sum_{j=0}^{n-1}a_{ij}x_j,\n",
    "$$\n",
    "\n",
    "which leads to\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f_i}{\\partial x_j}= a_{ij},\n",
    "$$\n",
    "\n",
    "and written out in terms of the vector $\\boldsymbol{x}$ we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}= \\boldsymbol{A}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8a4e6",
   "metadata": {},
   "source": [
    "## Exercise 1 - Finding the derivative of Matrix-Vector expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a2270",
   "metadata": {},
   "source": [
    "**a)** Consider the expression\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{x})}{\\partial \\boldsymbol{x}},\n",
    "$$\n",
    "\n",
    "Where $\\boldsymbol{a}$ and $\\boldsymbol{x}$ are column-vectors with length $n$.\n",
    "\n",
    "What is the *shape* of the expression we are taking the derivative of?\n",
    "\n",
    "Answer: $\\boldsymbol{a}^T\\boldsymbol{x}$ is a scalar (inner product of $\\boldsymbol{a}$ and $\\boldsymbol{x}$).\n",
    "\n",
    "What is the *shape* of the thing we are taking the derivative with respect to?\n",
    "\n",
    "Answer: $\\boldsymbol{x}$ is a vector with length n.\n",
    "\n",
    "What is the *shape* of the result of the expression?\n",
    "\n",
    "Answer: Differentiating a scalar with respect to a vector returns a vector, so the derivative is a vector of length n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0396734",
   "metadata": {},
   "source": [
    "**b)** Show that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{x})}{\\partial \\boldsymbol{x}} = \\boldsymbol{a}^T,\n",
    "$$\n",
    "\n",
    "Answer:\n",
    "$\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{x})}{\\partial \\boldsymbol{x}}$ is the gradient of $\\boldsymbol{a}^T\\boldsymbol{x}$ with respect to $\\boldsymbol{x}$, which by definition is a row vector with length equal to that of $\\boldsymbol{x}$.\n",
    "The elements of this row vector can be found by first considering that $\\boldsymbol{a}^T\\boldsymbol{x} = \\Sigma_i a_i x_i$. Thus, the elements of the gradient are \n",
    "$$\n",
    "(\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{x})}{\\partial \\boldsymbol{x}})_i = \\frac{\\partial}{\\partial x_i}(\\Sigma_j a_j x_j) = a_i,\n",
    "$$\n",
    "which are just the elements of $\\boldsymbol{a}$. Since the gradient is a row vector with elements equal to  $\\boldsymbol{a}$, then\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{x})}{\\partial \\boldsymbol{x}} = \\boldsymbol{a}^T .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc39d541",
   "metadata": {},
   "source": [
    "**c)** Show that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{a}^T\\boldsymbol{A}\\boldsymbol{a})}{\\partial \\boldsymbol{a}} = \\boldsymbol{a}^T(\\boldsymbol{A}+\\boldsymbol{A}^T).\n",
    "$$\n",
    "\n",
    "Answer: $\\boldsymbol{a}^T\\boldsymbol{A}\\boldsymbol{a})$ is a scalar that we can name $\\alpha$. \n",
    "$\\alpha$ will by the rules of matrix multiplication have the value\n",
    "$$\n",
    "    \\alpha = \\Sigma_{i,j} a_i A_{ij} a_j.\n",
    "$$\n",
    "Like we argued in b, the gradient of a scalar is a row vector, which we will name $w^T$.The elements of $w$ can be found by \n",
    "$$\n",
    "    w^T_k = \\frac{\\partial \\alpha}{\\partial a_k} = \\frac{\\partial}{\\partial a_k} (\\Sigma_{i,j} a_i A_{ij} a_j) = \\Sigma_i a_i A_{ik} + \\Sigma_j a_j A_{kj}.\n",
    "$$\n",
    "Furthermore, the rules of matrix multiplication imply that $(a^T A)_k = \\Sigma_i a_i A_{ik}$ and that $(a^T A^T)_k = \\Sigma_j a_j A_{kj}$. Thus, we can identify these terms in the expression for $w^T_k$, \n",
    "$$\n",
    "    w^T_k =(a^T A)_k + (a^T A^T)_k \\Rightarrow w^T = (a^T A) + (a^T A^T) = a^T(A+A^T),\n",
    "$$\n",
    "which completes the proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67d306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498d13ec",
   "metadata": {},
   "source": [
    "## Exercise 2 - Deriving the expression for OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f771de",
   "metadata": {},
   "source": [
    "The ordinary least squares method finds the parameters $\\boldsymbol{\\theta}$ which minimizes the squared error between our model $\\boldsymbol{X\\theta}$ and the true values $\\boldsymbol{y}$.\n",
    "\n",
    "To find the parameters $\\boldsymbol{\\theta}$ which minimizes this error, we take the derivative of the squared error expression with respect to $\\boldsymbol{\\theta}$, and set it equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49690237",
   "metadata": {},
   "source": [
    "**a)** Very briefly explain why the approach above finds the parameters $\\boldsymbol{\\theta}$ which minimizes this error.\n",
    "\n",
    "Answer: The argument for which the derivative is zero, is the location of an extremal point. Since the squared error is a parabola, it has at most one extremal point. And since the mean squared error by definition is larger than or equal to zero, the extremal point has to be a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cccc9d",
   "metadata": {},
   "source": [
    "We typically write the squared error as\n",
    "\n",
    "$$\n",
    "\\vert\\vert\\boldsymbol{y} - \\boldsymbol{X\\theta}\\vert\\vert^2\n",
    "$$\n",
    "\n",
    "which we can rewrite in matrix-vector form as\n",
    "\n",
    "$$\n",
    "\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbecf74",
   "metadata": {},
   "source": [
    "**b)** If $\\boldsymbol{X}$ is invertible, what is the expression for the optimal parameters $\\boldsymbol{\\theta}$? (**Hint:** Don't compute any derivatives, but solve $\\boldsymbol{X\\theta}=\\boldsymbol{y}$ for $\\boldsymbol{\\theta}$)\n",
    "\n",
    "Answer: If $\\boldsymbol{X}$ is invertible, then $\\boldsymbol{\\theta} = \\boldsymbol{X}^{-1}\\boldsymbol{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37af8f0",
   "metadata": {},
   "source": [
    "**c)** Show that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)^T\\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)}{\\partial \\boldsymbol{s}} = -2\\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)^T\\boldsymbol{A},\n",
    "$$\n",
    "\n",
    "Answer: define $\\boldsymbol{w}=\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}$.\n",
    "$\\boldsymbol{w}^T\\boldsymbol{w} = ||\\boldsymbol{w}||^2=\\Sigma_i w^2_i$.\n",
    "By the chain rule,\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{w}^T\\boldsymbol{w})}{\\partial s} = \\frac{\\partial (\\boldsymbol{w}^T\\boldsymbol{w})}{\\partial \\boldsymbol{w}} \\frac{\\partial \\boldsymbol{w}}{\\partial \\boldsymbol{s}}.\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\partial (\\boldsymbol{w}^T\\boldsymbol{w})}{\\partial \\boldsymbol{w}} = 2 \\boldsymbol{w}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial \\boldsymbol{w}}{\\partial \\boldsymbol{s}} = -\\boldsymbol{A}\n",
    "$$\n",
    "$$\n",
    " \\Rightarrow \\frac{\\partial (\\boldsymbol{w}^T\\boldsymbol{w})}{\\partial s} = 2 \\boldsymbol{w}^T*(-\\boldsymbol{A}) \\Rightarrow \\frac{\\partial \\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)^T\\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)}{\\partial \\boldsymbol{s}} = -2\\left(\\boldsymbol{x}-\\boldsymbol{A}\\boldsymbol{s}\\right)^T\\boldsymbol{A}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fca4d",
   "metadata": {},
   "source": [
    "**d)** Using the expression from **c)**, but substituting back in $\\boldsymbol{\\theta}$, $\\boldsymbol{y}$ and $\\boldsymbol{X}$, find the expression for the optimal parameters $\\boldsymbol{\\theta}$ in the case that $\\boldsymbol{X}$ is not invertible, but $\\boldsymbol{X^T X}$ is, which is most often the case.\n",
    "$$\n",
    "\\frac{\\partial (\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta})^T (\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta})}{\\partial \\theta} = -2 (\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta})^T\\boldsymbol{X}=0\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\boldsymbol{X}^T(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}) = 0 \\Rightarrow \\boldsymbol{X}^T \\boldsymbol{y} = \\boldsymbol{X}^T \\boldsymbol{X} \\boldsymbol{\\theta}\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\boldsymbol{\\hat{\\theta}_{OLS}} = (\\boldsymbol{X}^T\\boldsymbol{X})^{-1}\\boldsymbol{X}^T\\boldsymbol{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca3d74",
   "metadata": {},
   "source": [
    "## Exercise 3 - Creating feature matrix and implementing OLS using the analytical expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc179f7",
   "metadata": {},
   "source": [
    "With the expression for $\\boldsymbol{\\hat{\\theta}_{OLS}}$, you now have what you need to implement OLS regression with your input data and target data $\\boldsymbol{y}$. But before you can do that, you need to set up you input data as a feature matrix $\\boldsymbol{X}$.\n",
    "\n",
    "In a feature matrix, each row is a datapoint and each column is a feature of that data. If you want to predict someones spending based on their income and number of children, for instance, you would create a row for each person in your dataset, with the montly income and the number of children as columns.\n",
    "\n",
    "We typically also include an intercept in our models. The intercept is a value that is added to our prediction regardless of the value of the other features. The intercept tries to account for constant effects in our data that are not dependant on anything else. In our current example, the intercept could account for living expenses which are typical regardless of income or childcare expenses.\n",
    "\n",
    "We calculate the optimal intercept by including a feature with the constant value of 1 in our model, which is then multplied by some parameter $\\theta_0$ from the OLS method into the optimal intercept value (which will be $\\theta_0$). In practice, we include the intercept in our model by adding a column of ones to the start of our feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ff2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cf2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "income = np.array([116., 161., 167., 118., 172., 163., 179., 173., 162., 116., 101., 176., 178., 172., 143., 135., 160., 101., 149., 125.])\n",
    "children = np.array([5, 3, 0, 4, 5, 3, 0, 4, 4, 3, 3, 5, 1, 0, 2, 3, 2, 1, 5, 4])\n",
    "spending = np.array([152., 141., 102., 136., 161., 129.,  99., 159., 160., 107.,  98., 164., 121.,  93., 112., 127., 117.,  69., 156., 131.])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da61481",
   "metadata": {},
   "source": [
    "**a)** Create a feature matrix $\\boldsymbol{X}$ for the features income and children, including an intercept column of ones at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad87a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((n, 3))\n",
    "X[:, 0] = np.ones(n) # intercept column\n",
    "X[:, 1] = income\n",
    "X[:, 2] = children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddfac2",
   "metadata": {},
   "source": [
    "**b)** Use the expression from **3d)** to find the optimal parameters $\\boldsymbol{\\hat{\\beta}_{OLS}}$ for predicting spending based on these features. Create a function for this operation, as you are going to need to use it a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3f68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_parameters(X, y):\n",
    "    inverse = np.linalg.inv(np.matmul(X.T,X))\n",
    "    XTy = np.matmul(X.T, y)\n",
    "    return np.matmul(inverse,XTy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21181d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beta = OLS_parameters(X, spending)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6da80",
   "metadata": {},
   "source": [
    "## Exercise 4 - Fitting a polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71015064",
   "metadata": {},
   "source": [
    "In this course, we typically do linear regression using polynomials, though in real world applications it is also very common to make linear models based on measured features like you did in the previous exercise.\n",
    "\n",
    "When fitting a polynomial with linear regression, we make each polynomial degree($x, x^2, x^3, ..., x^p$) its own feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7476c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(-3, 3, n)\n",
    "y = np.exp(-x**2) + 1.5 * np.exp(-(x-2)**2) + np.random.normal(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321451b",
   "metadata": {},
   "source": [
    "**a)** Create a feature matrix $\\boldsymbol{X}$ for the features $x, x^2, x^3, x^4, x^5$, including an intercept column of ones at the start. Make this into a function, as you will do this a lot over the next weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91496e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(x, p):\n",
    "    n = len(x)\n",
    "    X = np.zeros((n, p + 1)) # p+1 because we include the intercept\n",
    "    for i in range(p+1):\n",
    "        X[:,i] = x**i\n",
    "    return X\n",
    "    #X[:, 0] = ...\n",
    "    #X[:, 1] = ...\n",
    "    #X[:, 2] = ...\n",
    "    # could this be a loop?\n",
    "\n",
    "X = polynomial_features(x, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b1e31",
   "metadata": {},
   "source": [
    "**b)** Use the expression from **3d)** to find the optimal parameters $\\boldsymbol{\\hat{\\beta}_{OLS}}$ for predicting $\\boldsymbol{y}$ based on these features. If you have done everything right so far, this code will not need changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034f502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = OLS_parameters(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703f788",
   "metadata": {},
   "source": [
    "**c)** Like in exercise 4 last week, split your feature matrix and target data into a training split and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29171358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3509f",
   "metadata": {},
   "source": [
    "**d)** Train your model on the training data(find the parameters which best fit) and compute the MSE on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e346f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_train = 0.014105689185902185\n",
      "MSE_test = 0.012261751072572737\n"
     ]
    }
   ],
   "source": [
    "beta_train = OLS_parameters(X_train, y_train) # \"train\" the model by finding the optimal parameters for theta analytically\n",
    "def MSE(X,y,beta):\n",
    "    n=len(y)\n",
    "    vector = y-np.linalg.matmul(X,beta)\n",
    "    return 1/n*np.inner(vector,vector)\n",
    "\n",
    "MSE_train = MSE(X_train,y_train,beta_train)\n",
    "MSE_test = MSE(X_test,y_test,beta_train)\n",
    "\n",
    "print(f\"MSE_train = {MSE_train}\")\n",
    "print(f\"MSE_test = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e431889",
   "metadata": {},
   "source": [
    "**e)** Do the same for each polynomial degree from 2 to 10, and plot the MSE on both the training and test data as a function of polynomial degree. The aim is to reproduce Figure 2.11 of [Hastie et al](https://github.com/CompPhysics/MLErasmus/blob/master/doc/Textbooks/elementsstat.pdf). Feel free to read the discussions leading to figure 2.11 of Hastie et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceb57457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poldegrees = [2,3,4,5,6,7,8,9,10]\n",
    "MSE_test_list = []\n",
    "MSE_train_list = []\n",
    "for p in poldegrees:\n",
    "    Xp = polynomial_features(x, p)\n",
    "    Xp_train, Xp_test, y_train, y_test = train_test_split(Xp,y,test_size=0.2)\n",
    "    betap = OLS_parameters(Xp_train, y_train)\n",
    "\n",
    "    MSE_test_list.append(MSE(Xp_test,y_test,betap))\n",
    "    MSE_train_list.append(MSE(Xp_train,y_train,betap))\n",
    "\n",
    "\n",
    "#### Plot ######\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(poldegrees,MSE_train_list, 'c-',label=\"Training sample\")\n",
    "plt.plot(poldegrees,MSE_test_list,'r-', label=\"Test sample\")\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b5954",
   "metadata": {},
   "source": [
    "**f)** Interpret the graph. Why do the lines move as they do? What does it tell us about model performance and generalizability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2acfb9",
   "metadata": {},
   "source": [
    "The MSE seems to decrease with higher polynomial degree for both samples, although there is more variation in the test sample. This makes sense, as the fit with the gaussian functions in this example in theory should improve with higher polynomial degree. The fit will not be perfect, because of the random noise that is included. The model seems to improve with higher complexity. The main limitation with this approach is that the $\\boldsymbol{X}^T\\boldsymbol{X}$ matrix is not always invertible, and the inversion could have large computational cost for large matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994f0c5",
   "metadata": {},
   "source": [
    "## Exercise 5 - Comparing your code with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f595b7a",
   "metadata": {},
   "source": [
    "When implementing different algorithms for the first time, it can be helpful to double check your results with established implementations before you go on to add more complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab310c1",
   "metadata": {},
   "source": [
    "**a)** Make sure your `polynomial_features` function creates the same feature matrix as sklearns PolynomialFeatures.\n",
    "\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b964d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.55271368e-15\n",
      "  -1.42108547e-14  5.68434189e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.55271368e-15\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.84217094e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.10542736e-15 -1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.77635684e-15\n",
      "   7.10542736e-15  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.10542736e-15 -1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.77635684e-15\n",
      "  -3.55271368e-15  7.10542736e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.77635684e-15\n",
      "  -3.55271368e-15  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.77635684e-15\n",
      "  -3.55271368e-15  7.10542736e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  8.88178420e-16\n",
      "  -1.77635684e-15  3.55271368e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  8.88178420e-16\n",
      "  -1.77635684e-15  3.55271368e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  4.44089210e-16\n",
      "  -8.88178420e-16  1.77635684e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.88178420e-16 -8.88178420e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.22044605e-16\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.55111512e-17  2.77555756e-17]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.46944695e-18  1.73472348e-18]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.67361738e-19]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.42101086e-20]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.35525272e-20  8.47032947e-22]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.35525272e-20 -8.47032947e-22]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.42101086e-20]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.67361738e-19  2.16840434e-19]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  6.93889390e-18\n",
      "   1.73472348e-18  8.67361738e-19]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.46944695e-18 -1.73472348e-18]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.77555756e-17  2.77555756e-17]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.55111512e-17\n",
      "  -5.55111512e-17 -2.77555756e-17]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.22044605e-16\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -4.44089210e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -4.44089210e-16 -4.44089210e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.44089210e-16\n",
      "  -8.88178420e-16 -8.88178420e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.88178420e-16\n",
      "  -8.88178420e-16  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.77635684e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  3.55271368e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.88178420e-16\n",
      "  -1.77635684e-15 -3.55271368e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.77635684e-15\n",
      "  -3.55271368e-15 -7.10542736e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.77635684e-15\n",
      "  -3.55271368e-15  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.77635684e-15\n",
      "  -3.55271368e-15 -7.10542736e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.55271368e-15  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.77635684e-15\n",
      "   7.10542736e-15  1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -7.10542736e-15 -1.42108547e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.10542736e-15  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.55271368e-15\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.55271368e-15\n",
      "  -1.42108547e-14 -5.68434189e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "skl_polyfeatures = PolynomialFeatures(5) # testing for degree 5 \n",
    "print(skl_polyfeatures.fit_transform(x.reshape(n,1))-X) # check difference between the matrix X we generated earlier and the one generated by scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bcfe9",
   "metadata": {},
   "source": [
    "The difference between the two matrices is practically zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c32c52",
   "metadata": {},
   "source": [
    "**b)** Make sure your `OLS_parameters` function computes the same parameters as sklearns LinearRegression with fit_intercept set to False, since the intercept is included in the feature matrix. Use `your_model_object.coef_` to extract the computed parameters.\n",
    "\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b04126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.66133815e-16  1.04916076e-14  1.76247905e-15 -6.27969898e-15\n",
      " -1.94289029e-16  6.26235175e-16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression(fit_intercept=False) # initialize object with fit_intercept=False\n",
    "linreg.fit(X,y)\n",
    "beta = OLS_parameters(X,y)\n",
    "print(linreg.coef_-beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8cc4a",
   "metadata": {},
   "source": [
    "The difference between the parameters calculated by OLS_parameters and the one calculated by scikitlearn is negligable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db8d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
